---
short_name: Project_1
name: Classification of two-camera corresponded bubble images
date: 2021-12-01
excerpt_separator: <!--more-->
---

Tracer particles like small bubbles are typically used to visualize airflow in Fluid Mechanics. 
To track the trajectories of bubbles, multiple cameras are needed to reconstruct the 3D coordinates of bubbles.
Before 3D reconstruction of bubbles' coordinates, it is important to correctly identify the images of each bubble across multiple cameras.  
This is a difficult task because small bubbles all look similar in cameras. To help identify corresponded bubble images in cameras 
(belong to each other (belong to a real bubble), several machine learning classifiers were used to predict the "True" or "False" of a bubble images pair. 
The results show that the neural network classifier (nn_clf) performed the best and achieved approximately 95% prediction accuracy. 

 <!--more-->


 <h2>Introduction</h2>
 <p>
     It may sounds weired that why somebody wants to study bubbles? 
     Actually, my entire PhD research was about using bubbles to visualize airflow movement.
     The bubbles we use are no different than what children play with except the bubbles are reall small (~1 mm),
     and they are filled with Helium to have the same density with air. 
     To visualize airflow, tracer particles like bubbles are added into the air as shown in Fig. 1 (a). 
     If the positions of bubbles are known in a sequence of time, 
     we can derive the velocities of bubbles, which are similar to the local airflow velocities. 
     To get the positions (3D coordinates) of bubbles, 
     the 3D reconstruction using multi-camera and triangulation is used as shown in Fig. 2 (b). 
     An example of measured velocity field can be found in Fig. 1 (c). 
     This figure shows that the mean velocity close to the nozzle is faster than the far field, 
     which corresponds well with our common sense.   
 </p>
 
 <p align="center">
     <img src="{{site.baseurl}}/assets/images/project_1/Fig-1.gif" alt="bubbles" height=500 width=250> <img src="{{site.baseurl}}/assets/images/project_1/Fig-1b.png" alt="diagram" height=500 width=500>
     <br>
     Fig. 1 (a) Bubbles in the airflow out of a nozzle. (b) Multiple cameras capturing bubbles' images. (c) Measured velocity field.
 </p>
 
 <p>
     Measuring accurate 3D coordinates of bubbles at each time step is the most important task,
     however, before the 3D reconstruction, we have to perform correspondence first.
     The <a href="https://en.wikipedia.org/wiki/Correspondence_problem">"correspondence"</a> here referes to a fundamental problem 
     in computer vision: when capturing the same object from different point of view, 
     how to determining which part of image 1 corresponds to which part in image 2.
     In this case, we would like to know which bubble image in image 2 corresponds to a bubble in image 1. 
     Typically, only two cameras are enough to reconstruct 3D coordinates (just like we have two eyes so we can sense the depth).
     However, ambiguities exist when corresponding 2D particle images using only two cameras as shown in Fig. 2 (a).  
     For particle X<sub>L</sub> in left image, there exists multiple candidates in right image that might correspond to X<sub>L</sub>.
     One way to determine the correct candidate is to extract the local features of each candidate using different methods such as 
     <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">SIFT</a> then compare to the features of X<sub>L</sub>.
     This is a common method in <a href="https://en.wikipedia.org/wiki/Panorama">panorama creation</a> or 
     <a href="https://en.wikipedia.org/wiki/Image_stitching">image stitching</a>.
     However, this method might not fit our task very well because all bubble images look very similar in each image.
     And because bubbles are transparent, their features vary a lot from different point of views. 
     One way to reduce ambiguities of bubbles is to add extra cameras so that one particle being occluded in a camera might be visible
     in another camera. As shown in Fig. 2 (b), for a particle in camera 1, extra cameras reduce the number of candidates by a lot. 
     Although this is a common approach when dealing with bubbles, extra cameras generate large data and cost more computing resources.
 </p>
 
 <p align="center">
     <img src="{{site.baseurl}}/assets/images/project_1/Fig-2.jpg" alt="correspondence" height=350 width=400> <img src="{{site.baseurl}}/assets/images/project_1/Fig-2b.gif" alt="fourCameras" height=350 width=400>
     <br>
     Fig. 2 (a) Correspondence of particles between two cameras. (b) Correspondence between multiple cameras.
 </p>
 
 <p>
     Therefore, we wonder that if there exists another way to determine the correspondence of bubbles using only two cameras.
     Machine learning has been more and more popular these days because it can utilize Big Data to solve real problems. 
     A model can be trained with data to perform classification or regression tasks. 
     In this case, we would like to find a classification model that can predict if a pair of bubbles from two images is a true correspodence.
     The usage of this model is shown in Fig. 3. 
     Instead of using four cameras, when we have a candidate pair from camera 1 and camera 2, 
     we can extract the features then pass the features to the prediction model. 
     If these two particles are projected from a single 3D particle (two 2D particles are corresponded), 
     the prediction label would be TRUE. 
     In contrast, if the prediction result is FALSE, then this pair of particles are not corresponded because they are 
     2D projections from different 3D particles.   
 </p>
 
 <p align="center">
     <img src="{{site.baseurl}}/assets/images/project_1/Fig-3.gif" alt="model" height=350 width=400>
     <br>
     Fig. 3 The model used to predict if two 2D particles are corresponded.
 </p>
 
 <h2>Methods</h2>
 <p>
     Now we know how to use this model, however, we need some ground truth data to train this model first. 
     It is a little bit tricky to get the ground truth training data because we do not know the real 3D positions of bubbles 
     in the measurement volume. 
     What we can do is to use some reasonable accurate results from other methods such as using four cameras to reconstruct 
     the position of bubbles. 
     This is an acceptable method because when there are few particles in the measurement volume, 
     the four-camera correspondence can be considered accurate because typically there is only 1-3 particle candidates when there 
     are less than 100 particles in a 1280*1024 image. 
     The construction of training data is shown in Fig. 4, 
     which shows how we extract the "True" and "False" data to train the model. 
     The basic procedure is as follows:
     <ol>
        <li>For particle a in camera 1, we can find the true correspondence particle b in camera 2, which is determined by method described in Fig. 2 (b). 
            This can be expressed as TC&lt;P<sub>a</sub>, P<sub>b</sub>&gt;, where P<sub>i</sub> refers to the i'th particle in each image.
        </li>
        <li>Except one true correspondence, there could exist false correspondences FC&lt;P<sub>a</sub>, P<sub>c</sub>&gt;, 
            where P<sub>c</sub> is another particle that also satisfies epipolar constraint with particle a.
        </li>
        <li>
            By iterating all true and false correspondences and extracting the features of each correspondence, 
            a training dataset D={(<b>x</b><sub>1</sub>, y<sub>1</sub>)......(<b>x</b><sub>m</sub>, y<sub>m</sub>)}, 
            where <b>x</b><sub>i</sub> is the i'th training data sample, y is the label of data sample, and m is the number of data samples.
        </li>
        <li>
            Train a model f so that y&#770; = f(<b>x</b>), where y&#770; is the predicted label indicating if this correspondence is true or false.
            The training data was used to train four different kinds of classifiers:
            <ul>
                <li>logistic regression (LR)</li>
                <li>Decision tree (DT)</li>
                <li>neural network (NN) - Multi Layer Perceptron</li>
                <li>Support Vector Machine (SVM)</li>
            </ul> 
        </li>
      </ol>

     
 </p>
 
 <p align="center">
     <img src="{{site.baseurl}}/assets/images/project_1/Fig-4.gif" alt="model" height=360 width=480>
     <br>       
     Fig. 4 Supervised training of model using True and False data.
 </p>
 
 <p>
     After extraction, an array containing 64 features (columns) was extracted. 
     However, there were some linear dependencies between different features. 
     To reduce the feature dimension, principal components analysis (PCA) was performed on the array with ten principal components. 
     It can be seen in Fig.5 that the true and false samples were seperated after PCA. 
     The explained variance was approximately 70%.   
 </p>
 
 <p align="center">
     <img src="{{site.baseurl}}/assets/images/project_1/Fig-5.png" alt="model" height=360 width=480>
     <br>
     Fig. 5 The biplot of True and False data points after PCA transformation.
 </p>
  
 <h2>Results</h2>
 <p>
    Since the classifier is going to be used in real-time measurement, 
    we would like to select the classifier that has the fastest prediction time but also with reasonable accuracy. 
    All models were initiated with the default settings. 
    The accuracies and predictions time are shown in Fig. 6. 
    It can be seen that the neural network classifier achieved the best accuracy (~97%). 
    However, the logistic regression classifier was the fastest one (less than 0.01s per 150000 samples). 
    Therefore, when high accuracy is needed, the neural network classifier should be selected. 
    When the processing time is the primary consideration, the logistic regression classifier can be used.
 </p>
 
 <p align="center">
     <img src="{{site.baseurl}}/assets/images/project_1/Fig-6.png" alt="model" height=360 width=480>
     <br>
     Fig. 6 The accuracies and prediction time of different classifiers.
 </p>
 
 <h2>Conclusion</h2>
 <p>
     Based on the results, we found that it is possible to use machine learning method to enhance the two-camera 
     correspondence in airflow visualization and measurement using tracer bubbles, 
     which was typically achieved by traditional computer vision method such as triangulation. 
     This is a meaningful project because by reducing the required number of cameras using machine learning,
     the measurement volume can be greatly increased with the same number of cameras. 
 </p>